{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "okHUdVTzIiI_"
   },
   "outputs": [],
   "source": [
    "#Packages to use pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "#Packages to data management\n",
    "from sklearn import metrics\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NVtnnf6tMYFa"
   },
   "outputs": [],
   "source": [
    "#We explicitly set the random seed in order to get the same results in each run\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "APTB-mrY4FZ6",
    "outputId": "5cd12690-c28d-4303-ac8c-a11bcfa333a7"
   },
   "outputs": [],
   "source": [
    "#Load data\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    ")\n",
    "train_labels = np.array([k[1] for k in train_data])\n",
    "train_data = np.array([np.array(k[0]) for k in train_data])\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    ")\n",
    "test_labels = np.array([k[1] for k in test_data])\n",
    "test_data = np.array([np.array(k[0]) for k in test_data])\n",
    "\n",
    "#Convert data to vector representation\n",
    "train_data = train_data.reshape((train_data.shape[0], 784))\n",
    "test_data = test_data.reshape((test_data.shape[0], 784))\n",
    "\n",
    "#Compute the mean and standard deviation of the dataset\n",
    "mean = train_data.astype(np.float32).mean()/255\n",
    "std = train_data.astype(np.float32).std()/255\n",
    "\n",
    "#Normalize data\n",
    "train_data = (train_data.astype(np.float32) - mean)/std\n",
    "test_data = (test_data.astype(np.float32) - mean)/std\n",
    "\n",
    "#Pack data with labels\n",
    "train_data = list(zip(train_data, train_labels))\n",
    "test_data = list(zip(test_data, test_labels))\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yr0OXOJqO6wY"
   },
   "outputs": [],
   "source": [
    "#Function to plot images in a matrix layout\n",
    "def plot_images(images):\n",
    "  num_images = len(images)\n",
    "\n",
    "  rows = int(np.sqrt(num_images))\n",
    "  cols = int(np.sqrt(num_images))\n",
    "\n",
    "  fig = plt.figure()\n",
    "\n",
    "  for i in range(rows*cols):\n",
    "    ax = fig.add_subplot(rows, cols, i+1)\n",
    "    ax.imshow(images[i].reshape((28,28)), cmap='bone')\n",
    "    ax.axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_1zfxYE_Pa-h"
   },
   "outputs": [],
   "source": [
    "#Plot images\n",
    "N_IMAGES = 25\n",
    "\n",
    "images = [image for image, labels in [train_data[i] for i in range(N_IMAGES)]]\n",
    "\n",
    "plot_images(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "32A89mSRPumQ",
    "outputId": "106e3b50-6200-48b2-ad00-df29fa06b8bb"
   },
   "outputs": [],
   "source": [
    "#Split train data into TRAIN + VALIDATION (10% of the data as validation)\n",
    "VALID_RATIO = 0.9\n",
    "\n",
    "n_train_examples = int(len(train_data) * VALID_RATIO)\n",
    "n_valid_examples = len(train_data) - n_train_examples\n",
    "\n",
    "train_data, valid_data = data.random_split(train_data, [n_train_examples, n_valid_examples])\n",
    "\n",
    "print(f'Num. training examples: {len(train_data)}')\n",
    "print(f'Num. validation examples: {len(valid_data)}')\n",
    "print(f'Num. testing examples: {len(test_data)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EEZUWGe9QqUH"
   },
   "outputs": [],
   "source": [
    "#Plot validation data\n",
    "N_IMAGES = 25\n",
    "\n",
    "images = [image for image, labels in [valid_data[i] for i in range(N_IMAGES)]]\n",
    "\n",
    "plot_images(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JNeKJyelRZq3"
   },
   "outputs": [],
   "source": [
    "#Pytorch has a nice feature to prepare data. The DataLoader creates an iterator of batches which are very convenient for training\n",
    "#Set the batch size the biggest value as possible depending on your GPU. Operations in a batch are parallelized.\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_iterator = data.DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE)\n",
    "valid_iterator = data.DataLoader(valid_data, batch_size=BATCH_SIZE)\n",
    "test_iterator = data.DataLoader(test_data, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J7rQ7f7zSGiI"
   },
   "outputs": [],
   "source": [
    "#Class for our neural network. When a class inherits from torch.nn.Module,\n",
    "#it automatically becomes a neural network\n",
    "\n",
    "class MLP(nn.Module):\n",
    "  # We need to define two methods at leats: constructor and forward\n",
    "\n",
    "  #Constructor is for member definitions\n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super().__init__()\n",
    "\n",
    "    self.fc1 = nn.Linear(input_dim, 250)\n",
    "    self.fc2 = nn.Linear(250, 100)\n",
    "    self.fc3 = nn.Linear(100, output_dim)\n",
    "\n",
    "  #Forward: what happens when we feed the network with data\n",
    "  def forward(self, input):\n",
    "    batch_size = input.shape[0]\n",
    "    input = input.view(batch_size, -1)\n",
    "    h_1 = F.relu(self.fc1(input))\n",
    "    h_2 = F.relu(self.fc2(h_1))\n",
    "    y_pred = self.fc3(h_2)\n",
    "\n",
    "    #Our network returns the output of the final layer but also the output of the hidden layer\n",
    "    return y_pred, h_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bAlOiQVXTih3"
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "INPUT_DIM = 28*28\n",
    "OUTPUT_DIM = 10\n",
    "\n",
    "model = MLP(INPUT_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cNkItJUvUXc7",
    "outputId": "cc679305-9210-47ed-e14b-b1887d22e7f3"
   },
   "outputs": [],
   "source": [
    "#How many parameters are there in our model?\n",
    "\n",
    "def count_parameters(model):\n",
    "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t9XJ2j-5VPmC"
   },
   "outputs": [],
   "source": [
    "#Create the object for the optimization.\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4NwdyL4mczJk"
   },
   "outputs": [],
   "source": [
    "#Define the loss criterion\n",
    "#In Pytorch, the CrossEntropyLoss includes the softmax activation and the negative log-likelihood cost function\n",
    "#These two functions are joined because efficiency issues\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6qXkS3i3c-8H"
   },
   "outputs": [],
   "source": [
    "#In Pytorch we can decide where to run our program, so we can\n",
    "#initialize the device depending whether you have a GPU or not\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9XFHeUvBppkI"
   },
   "outputs": [],
   "source": [
    "#Send the model and the loss object to the GPU\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ow_vD69qpu_1"
   },
   "outputs": [],
   "source": [
    "#Function to compute the accuracy. We assume the predictions and the labels are tensors in the GPU\n",
    "\n",
    "def calculate_accuracy(y_pred, y):\n",
    "  top_pred = y_pred.argmax(1, keepdim=True)\n",
    "  correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "  acc = correct.float()/y.shape[0]\n",
    "  return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "awCNVwg2qKjt"
   },
   "outputs": [],
   "source": [
    "#Define a function to perform training\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, device):\n",
    "  epoch_loss = 0\n",
    "  epoch_acc = 0\n",
    "\n",
    "  #We have to set the neural network in training mode. This is because during\n",
    "  #training, we need gradients and complementary data to ease the computation\n",
    "  model.train()\n",
    "\n",
    "  #Training loop\n",
    "  for (x, y) in iterator:\n",
    "    x = x.to(device) #Data\n",
    "    y = y.long().to(device) #Labels\n",
    "\n",
    "    optimizer.zero_grad() #Clean gradients\n",
    "\n",
    "    y_pred, _ = model(x) #Feed the network with data\n",
    "\n",
    "    loss = criterion(y_pred, y) #Compute the loss\n",
    "\n",
    "    acc = calculate_accuracy(y_pred, y) #Compute the accuracy\n",
    "\n",
    "    loss.backward() #Compute gradients\n",
    "\n",
    "    optimizer.step() #Apply update rules\n",
    "\n",
    "    epoch_loss += loss.item()\n",
    "    epoch_acc += acc.item()\n",
    "\n",
    "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gWnLRPshqck0"
   },
   "outputs": [],
   "source": [
    "#Function to test neural network\n",
    "\n",
    "def evaluate(model, iterator, criterion, device):\n",
    "  epoch_loss = 0\n",
    "  epoch_acc = 0\n",
    "\n",
    "  #We put the network in testing mode\n",
    "  #In this mode, Pytorch doesn't use features only reserved for\n",
    "  #training (dropout for instance)\n",
    "  model.eval()\n",
    "\n",
    "  with torch.no_grad(): #disable the autograd engine (save computation and memory)\n",
    "\n",
    "    for (x, y) in iterator:\n",
    "      x = x.to(device)\n",
    "      y = y.long().to(device)\n",
    "\n",
    "      y_pred, _ = model(x)\n",
    "\n",
    "      loss = criterion(y_pred, y)\n",
    "\n",
    "      acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "      epoch_loss += loss.item()\n",
    "      epoch_acc += acc.item()\n",
    "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h7m0LmTOq3jT"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G8tlYD-Pq6mE",
    "outputId": "9db7875f-7fd5-4221-bf1b-77a52dd72878"
   },
   "outputs": [],
   "source": [
    "#Let's perform the training\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "  start_time = time.time()\n",
    "\n",
    "  #Train + validation cycles\n",
    "  train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)\n",
    "  valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, device)\n",
    "\n",
    "  #If we find a smaller loss, we save the model\n",
    "  if valid_loss < best_valid_loss:\n",
    "    best_valid_loss = valid_loss\n",
    "    torch.save(model.state_dict(), 'saved-model.pt')\n",
    "\n",
    "  end_time = time.time()\n",
    "\n",
    "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "  print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "  print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "  print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z933hEfcrB6L",
    "outputId": "af35824b-c21c-49b6-d8a2-1885399290d1"
   },
   "outputs": [],
   "source": [
    "#Load the best model\n",
    "model.load_state_dict(torch.load('saved-model.pt'))\n",
    "\n",
    "test_loss , test_acc = evaluate(model, test_iterator, criterion, device)\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T264_deKswlV"
   },
   "outputs": [],
   "source": [
    "#Function to get predictions over a dataset\n",
    "\n",
    "def get_predictions(model, iterator, device):\n",
    "\n",
    "    #For prediction, we also deactivate training features\n",
    "    model.eval()\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "\n",
    "            y_pred, _ = model(x)\n",
    "\n",
    "            #Remember that our network does not apply the softmax\n",
    "            #We have to do it explicitly for prediction\n",
    "            y_prob = F.softmax(y_pred, dim = -1)\n",
    "            top_pred = y_prob.argmax(1, keepdim = True)\n",
    "\n",
    "            #We store the images, their labels and the pdf of each sample\n",
    "            images.append(x.cpu())\n",
    "            labels.append(y.cpu())\n",
    "            probs.append(y_prob.cpu())\n",
    "\n",
    "    images = torch.cat(images, dim = 0)\n",
    "    labels = torch.cat(labels, dim = 0)\n",
    "    probs = torch.cat(probs, dim = 0)\n",
    "\n",
    "    return images, labels, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5jpX-Kb3t08m"
   },
   "outputs": [],
   "source": [
    "#Comute predictions and the label with the maximum probability\n",
    "images, labels, probs = get_predictions(model, test_iterator, device)\n",
    "\n",
    "pred_labels = torch.argmax(probs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CC4LMKpYt5Jo"
   },
   "outputs": [],
   "source": [
    "#Plot a confussion matrix\n",
    "def plot_confusion_matrix(labels, pred_labels):\n",
    "\n",
    "    fig = plt.figure(figsize = (10, 10));\n",
    "    ax = fig.add_subplot(1, 1, 1);\n",
    "    cm = metrics.confusion_matrix(labels, pred_labels);\n",
    "    cm = metrics.ConfusionMatrixDisplay(cm);\n",
    "    cm.plot(values_format = 'd', cmap = 'Blues', ax = ax)\n",
    "\n",
    "plot_confusion_matrix(labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UvTuvHuwuAeA"
   },
   "outputs": [],
   "source": [
    "#Number of correct predictions\n",
    "#Remember labels and predictions are tensors in GPU\n",
    "corrects = torch.eq(labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "re4wdlZluJVX"
   },
   "outputs": [],
   "source": [
    "#Collect the incorrect predictions\n",
    "incorrect_examples = []\n",
    "\n",
    "for image, label, prob, correct in zip(images, labels, probs, corrects):\n",
    "    if not correct:\n",
    "        incorrect_examples.append((image, label, prob))\n",
    "\n",
    "\n",
    "#The probability can represent a confidence as well, so we sort the incorrect samples\n",
    "#by using the degree of confidence\n",
    "\n",
    "#We want to know the samples in which the neural network is sure the prediction was perfect\n",
    "incorrect_examples.sort(reverse = True, key = lambda x: torch.max(x[2], dim = 0).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H1sE0imuuQ7f"
   },
   "outputs": [],
   "source": [
    "def plot_most_incorrect(incorrect, n_images):\n",
    "\n",
    "    rows = int(np.sqrt(n_images))\n",
    "    cols = int(np.sqrt(n_images))\n",
    "\n",
    "    fig = plt.figure(figsize = (20, 10))\n",
    "    for i in range(rows*cols):\n",
    "        ax = fig.add_subplot(rows, cols, i+1)\n",
    "        image, true_label, probs = incorrect[i]\n",
    "        true_prob = probs[true_label.item()]\n",
    "        incorrect_prob, incorrect_label = torch.max(probs, dim = 0)\n",
    "        ax.imshow(image.view(28, 28).cpu().numpy(), cmap='bone')\n",
    "        ax.set_title(f'true label: {true_label} ({true_prob:.2f})\\n' \\\n",
    "                     f'pred label: {incorrect_label} ({incorrect_prob:.2f})')\n",
    "        ax.axis('off')\n",
    "    fig.subplots_adjust(hspace= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KRb2PvNFuXyH"
   },
   "outputs": [],
   "source": [
    "N_IMAGES = 25\n",
    "\n",
    "plot_most_incorrect(incorrect_examples, N_IMAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eIAkeJzjuaoh"
   },
   "outputs": [],
   "source": [
    "#Function to compute the prediction and the intermediate representation of images\n",
    "def get_representations(model, iterator, device):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    outputs = []\n",
    "    intermediates = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "\n",
    "            y_pred, h = model(x)\n",
    "\n",
    "            #We will register the output + output of hidden layer per image\n",
    "            outputs.append(y_pred.cpu())\n",
    "            intermediates.append(h.cpu())\n",
    "            labels.append(y)\n",
    "\n",
    "    outputs = torch.cat(outputs, dim = 0)\n",
    "    intermediates = torch.cat(intermediates, dim = 0)\n",
    "    labels = torch.cat(labels, dim = 0)\n",
    "\n",
    "    return outputs, intermediates, labels\n",
    "\n",
    "#Function to reduce the dimensionality of data to dimension 2\n",
    "def get_pca(data, n_components = 2):\n",
    "    pca = decomposition.PCA()\n",
    "    pca.n_components = n_components\n",
    "    pca_data = pca.fit_transform(data)\n",
    "    return pca_data\n",
    "\n",
    "#Plot 2D representation\n",
    "def plot_representations(data, labels, n_images = None):\n",
    "    if n_images is not None:\n",
    "        data = data[:n_images]\n",
    "        labels = labels[:n_images]\n",
    "    fig = plt.figure(figsize = (10, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    scatter = ax.scatter(data[:, 0], data[:, 1], c = labels, cmap = 'tab10')\n",
    "    legend = ax.legend(*scatter.legend_elements())\n",
    "    ax.add_artist(legend)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v0aGfb9PvbQu"
   },
   "outputs": [],
   "source": [
    "#Let's see the representation of the output\n",
    "outputs, intermediates, labels = get_representations(model, train_iterator, device)\n",
    "output_pca_data = get_pca(outputs)\n",
    "plot_representations(output_pca_data, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qGroDL7pvyH9"
   },
   "outputs": [],
   "source": [
    "#ow, let's see the representation of the hidden layer\n",
    "intermediate_pca_data = get_pca(intermediates)\n",
    "plot_representations(intermediate_pca_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yui8eWErwD7F"
   },
   "outputs": [],
   "source": [
    "#We will use a different tool: t-SNE\n",
    "def get_tsne(data, n_components = 2, n_images = None):\n",
    "    if n_images is not None:\n",
    "        data = data[:n_images]\n",
    "    tsne = manifold.TSNE(n_components = n_components, random_state = 0)\n",
    "    tsne_data = tsne.fit_transform(data)\n",
    "    return tsne_data\n",
    "\n",
    "#t-SNE is computationally expensive, we only apply it on 5000 images\n",
    "N_IMAGES = 5_000\n",
    "\n",
    "output_tsne_data = get_tsne(outputs, n_images = N_IMAGES)\n",
    "plot_representations(output_tsne_data, labels, n_images = N_IMAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jkz1jhcWwRmM"
   },
   "outputs": [],
   "source": [
    "intermediate_tsne_data = get_tsne(intermediates, n_images = N_IMAGES)\n",
    "plot_representations(intermediate_tsne_data, labels, n_images = N_IMAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZnuWted3Ev3e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
